{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hdson07/SWContest/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzHfnf-VEbo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#개발 방향 -> 얼굴 detection 안됐을 때, 사람이 나갔을 때 박스 없어지도록\n",
        "\n",
        "\n",
        "import dlib, cv2\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "######################################################\n",
        "############face detection, face tracking#############\n",
        "######################################################\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "sp = dlib.shape_predictor('models/shape_predictor_68_face_landmarks.dat')\n",
        "facerec = dlib.face_recognition_model_v1('models/dlib_face_recognition_resnet_model_v1.dat')\n",
        "\n",
        "#descs = np.load('descs.npy)()\n",
        "\n",
        "def read_img(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img\n",
        "\n",
        "def find_faces(img):\n",
        "    dets = detector(img, 1) #얼굴 찾은 결과물 들어감.\n",
        "\n",
        "    if len(dets) == 0:\n",
        "        return np.empty(0), np.empty(0), np.empty(0)\n",
        "\n",
        "    rects, shapes = [], [] #얼굴 랜드마크 만들기 68개 점\n",
        "    shapes_np = np.zeros((len(dets), 68, 2), dtype = np.int)\n",
        "\n",
        "    for k,d in enumerate(dets): #얼굴 찾은 갯수 만큼 루프\n",
        "        rect = ( (d.left(), d.top()), (d.right(), d.bottom()) )\n",
        "        rects.append(rect)\n",
        "\n",
        "        shape = sp(img, d)\n",
        "\n",
        "        for i in range(0, 68):\n",
        "            shapes_np[k][i] = (shape.part(i).x, shape.part(i).y)\n",
        "\n",
        "        shapes.append(shape)\n",
        "\n",
        "    return rects, shapes, shapes_np\n",
        "\n",
        "def encode_faces(img, shapes): #얼굴 -> 128개의 벡터로 변환\n",
        "    face_descriptors = []\n",
        "\n",
        "    for shape in shapes:\n",
        "        face_descriptor = facerec.compute_face_descriptor(img, shape)\n",
        "        #전체 이미지랑, 랜드마크 입력해서 인코딩\n",
        "        face_descriptors.append(np.array(face_descriptor)) #array로 변환\n",
        "\n",
        "    return np.array(face_descriptors)\n",
        "\n",
        "def face_position(img):\n",
        "    dets = detector(img, 1)\n",
        "\n",
        "    if len(dets) == 0:\n",
        "        return np.empty(0)\n",
        "\n",
        "    for k, d in enumerate(dets):\n",
        "        print('Detection {}: LEFT: {} TOP: {} RIGHT: {} BOTTOM: {}'.format(k+1, d.left(), d.top(), d.right(), d.bottom()))\n",
        "        shape = sp(img, d)\n",
        "        face_descriptor = facerec.compute_face_descriptor(img, shape)\n",
        "\n",
        "        return np.array(face_descriptor)\n",
        "\n",
        "######################################################\n",
        "#####################Telegram API#####################\n",
        "######################################################\n",
        "import telegram\n",
        "my_token = '956782186:AAEDq7uyWt21NTk9asLc3ydS8GUhz5lphNQ'\n",
        "bot = telegram.Bot(token = my_token)\n",
        "\n",
        "\n",
        "def send_message(text):\n",
        "    bot.sendMessage(chat_id='858643842', text= text)\n",
        "\n",
        "\n",
        "###tracking###########################################\n",
        "#from __future__ import print_function\n",
        "trackerTypes = ['BOOSTING', 'MIL', 'KCF', 'TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
        "\n",
        "\n",
        "def createTrackerByName(trackerType):\n",
        "    # Create a tracker based on tracker name\n",
        "    if trackerType == trackerTypes[0]:\n",
        "        tracker = cv2.TrackerBoosting_create()\n",
        "    elif trackerType == trackerTypes[1]:\n",
        "        tracker = cv2.TrackerMIL_create()\n",
        "    elif trackerType == trackerTypes[2]:\n",
        "        tracker = cv2.TrackerKCF_create()\n",
        "    elif trackerType == trackerTypes[3]:\n",
        "        tracker = cv2.TrackerTLD_create()\n",
        "    elif trackerType == trackerTypes[4]:\n",
        "        tracker = cv2.TrackerMedianFlow_create()\n",
        "    elif trackerType == trackerTypes[5]:\n",
        "        tracker = cv2.TrackerGOTURN_create()\n",
        "    elif trackerType == trackerTypes[6]:\n",
        "        tracker = cv2.TrackerMOSSE_create()\n",
        "    elif trackerType == trackerTypes[7]:\n",
        "        tracker = cv2.TrackerCSRT_create()\n",
        "    else:\n",
        "        tracker = None\n",
        "        print('Incorrect tracker name')\n",
        "        print('Available trackers are:')\n",
        "        for t in trackerTypes:\n",
        "            print(t)\n",
        "\n",
        "    return tracker\n",
        "\n",
        "bboxes = []\n",
        "colors = []\n",
        "\n",
        "trackerType = \"CSRT\"\n",
        "# Create MultiTracker object\n",
        "multiTracker = cv2.MultiTracker_create()\n",
        "\n",
        "\n",
        "######################################################\n",
        "################variances#############################\n",
        "######################################################\n",
        "img_paths = {\n",
        "    'jihun' : 'images/jihun.JPG',\n",
        "    'sung' : 'images/Sung.jpeg' ,\n",
        "    'joon' : 'images/joon.JPG',\n",
        "    'criminal' : 'images/suho.jpeg'\n",
        "}\n",
        "\n",
        "descs = {\n",
        "    'jihun' : None,\n",
        "    'sung' : None ,\n",
        "    'joon' : None,\n",
        "    'criminal' : None\n",
        "}\n",
        "\n",
        "for name, img_path in img_paths.items():\n",
        "    img_bgr = cv2.imread(img_path)\n",
        "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    _, img_shapes, _ = find_faces(img_rgb) #landmark를 받아서\n",
        "    descs[name] = encode_faces(img_rgb, img_shapes)[0]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
        "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    exit()\n",
        "\n",
        "detectCounter = 0\n",
        "rects = []\n",
        "det_decs = {} #현재 detected 된 사람들의 decs를 추가\n",
        "det_names = [(0,0),(0,0),(0,0)]\n",
        "send = False\n",
        "\n",
        "rect_initial = 0\n",
        "rect_after = -1\n",
        "find_try = 1\n",
        "search = True\n",
        "tracking = False\n",
        "while True:\n",
        "    ret, img = cap.read()\n",
        "    if not ret:\n",
        "        print('not video')\n",
        "        break\n",
        "\n",
        "\n",
        "    img_rgb = img\n",
        "    img_bgr = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img_bgr = cv2.cvtColor(img_bgr, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    if detectCounter > 10:\n",
        "        cv2.imshow('Video', img_bgr)\n",
        "    else:\n",
        "        cv2.imshow('Video', img_rgb)\n",
        "\n",
        "\n",
        "    rects, shapes, _ = find_faces(img)  # 위치 계속 받아오고\n",
        "    rect_after = len(rects)\n",
        "\n",
        "    if rect_initial != rect_after:\n",
        "        search = True\n",
        "    print(search)\n",
        "\n",
        "    while search:\n",
        "        det_info = []\n",
        "        rects, shapes, _ = find_faces(img) #위치 계속 받아오고\n",
        "        img_encoded = encode_faces(img, shapes) #desc 계산하고\n",
        "        rect_initial = len(rects)\n",
        "\n",
        "        for i, desc in enumerate(img_encoded):\n",
        "            found = False\n",
        "\n",
        "            for name, saved_desc in descs.items():\n",
        "                dist = np.linalg.norm([desc] - saved_desc, axis = 1)\n",
        "\n",
        "                if dist < 0.6:\n",
        "                    det_names[i] = (name, rects[i])\n",
        "                    found = True\n",
        "                    break\n",
        "                else:\n",
        "                    det_names[i] =('Unknown', rects[i])\n",
        "\n",
        "        search = False\n",
        "\n",
        "\n",
        "    print(det_names)\n",
        "    print(rects)\n",
        "\n",
        "    while tracking == False :\n",
        "        for name, rect in det_names:\n",
        "            if name:\n",
        "                print('traking rectangle')\n",
        "                multiTracker.add(createTrackerByName(trackerType), img_rgb, (216, 68, 439, 291))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    success, boxes = multiTracker.update(img_rgb)\n",
        "\n",
        "    for i, newbox in enumerate(boxes):\n",
        "        p1 = (int(newbox[0]), int(newbox[1]))\n",
        "        p2 = (int(newbox[0] + newbox[2]), int(newbox[1] + newbox[3]))\n",
        "        cv2.rectangle(img_rgb, p1, p2, color=(255, 255, 255), thickness=2)\n",
        "\n",
        "\n",
        "    # while send == False:\n",
        "    #     print('a')\n",
        "    #     send = True\n",
        "    #     break\n",
        "\n",
        "    if detectCounter > 5:\n",
        "        cv2.imshow('Video', img_bgr)\n",
        "    else:\n",
        "        cv2.imshow('Video', img_rgb)\n",
        "\n",
        "    if cv2.waitKey(1) == ord('q') :\n",
        "        break\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}